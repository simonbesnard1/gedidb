{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# GEDIProcessor example with different parallel engines\n\nThis example demonstrates how to use the `gedidb` library to process GEDI granules \nwith different parallel engines, such as `concurrent.futures.ThreadPoolExecutor` and `dask.distributed.Client`.\n\nA default data configuration file (`data_config.yml`) can be downloaded here:\n\n:download:`Download data_config.yml <../_static/test_files/data_config.yml>`\n\nA default geojson file (`test.geojson`) can be downloaded here:\n\n:download:`Download test.geojson <../_static/test_files/test.geojson>`\n\n\nWe will:\n\n1. Set up configuration paths.\n2. Initialize different parallel engines (Dask and concurrent futures).\n3. Run the GEDIProcessor to process granules and consolidate fragments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import required libraries\nimport gedidb as gdb\nfrom dask.distributed import Client, LocalCluster\nimport concurrent.futures\n\n# Configuration file path\nconfig_file = '/path/to/data_config.yml'\n\n# Paths to GeoJSON region and EarthData credentials\ngeojson_path = '/path/to/test.geojson'\nearth_data_dir = '/path/to/EarthData_credentials'\n\n# Define the start and end date for processing\nstart_date = '2020-01-01'\nend_date = '2020-12-31'\n\n# Option 1: Using a ThreadPoolExecutor (concurrent.futures)\n# ---------------------------------------------------------\n# This option uses Python's standard library for parallel execution.\n# Useful for lightweight, multi-threaded tasks on a single machine.\nprint(\"Initializing ThreadPoolExecutor...\")\nconcurrent_engine = concurrent.futures.ThreadPoolExecutor(max_workers=5)\n\n# Option 2: Using Dask for Parallel Execution\n# -------------------------------------------\n# This option is suitable for distributed computing or managing memory more efficiently.\nprint(\"Initializing Dask Client...\")\nn_workers = 1  # Number of Dask workers\ncluster = LocalCluster(\n    n_workers=5,\n    threads_per_worker=1,\n    processes=True,\n    memory_limit='8GB',\n    dashboard_address=None,\n)\ndask_client = Client(cluster)\n\n# Initialize the GEDIProcessor with the chosen parallel engine\n# ------------------------------------------------------------\n# Here, we demonstrate usage with `concurrent.futures.ThreadPoolExecutor`. \n# You can replace `parallel_engine=concurrent_engine` with `parallel_engine=dask_client` to use Dask instead.\nwith gdb.GEDIProcessor(\n    config_file=config_file,\n    geometry=geojson_path,\n    start_date=start_date,\n    end_date=end_date,\n    earth_data_dir=earth_data_dir,\n    parallel_engine=concurrent_engine,  # Change to `parallel_engine=dask_client` for Dask\n) as processor:\n    # Run the GEDIProcessor to process granules and consolidate fragments\n    processor.compute(consolidate=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}